{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "Real number of items: 1000, Real number of users: 10000.\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "\n",
    "path_dataset = \"../Data/data_train.csv\"\n",
    "ratings = load_data(path_dataset).T # ratings: row = user, column = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 3, min # of users per item = 8.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    \n",
    "    num_items, num_users = valid_ratings.shape \n",
    "    \n",
    "    # create indices\n",
    "    index_split = int(np.floor((1 - p_test) * num_items))\n",
    "    indices = np.random.permutation(num_items)\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    \n",
    "    # create split\n",
    "    \n",
    "    train = valid_ratings[index_tr]\n",
    "    test = valid_ratings[index_te] \n",
    "    \n",
    "    train_full = valid_ratings[index_tr]\n",
    "    test_full = valid_ratings[index_te] \n",
    "        \n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    \n",
    "    return valid_ratings, train, test, valid_users, valid_items, train_full, test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1063554\n",
      "Total number of nonzero elements in test data:113319\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAA6CAYAAAAKqaYCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAiChuX/AVC15cm1jz44AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa24d438358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test, valid_users, valid_items, train_full, test_full = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    # initalization\n",
    "    num_items, num_users = train.shape\n",
    "    item_features = np.random.randn(num_features, num_items)\n",
    "    user_features = np.random.randn(num_features, num_users)\n",
    "    \n",
    "    # mean of for each item\n",
    "    sums_train = train.sum(axis=1).reshape(num_items,)\n",
    "    counts_train = np.diff(train.tocsr().indptr) # counts number of non zero value for each row\n",
    "    mean_train_item = sums_train / counts_train\n",
    "    \n",
    "    item_features[0,:] = mean_train_item\n",
    "    \n",
    "    return user_features, item_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "\n",
    "    # initalization\n",
    "    prediction = (item_features.T).dot(user_features)\n",
    "    x, y = zip(*nz)\n",
    "    \n",
    "    # remove zero elements\n",
    "    prediction_nz = prediction[x,y]\n",
    "    data_nz = data[x,y]\n",
    "        \n",
    "    # rmse    \n",
    "    return np.sqrt(calculate_mse(data_nz, prediction_nz).sum() / (data.nnz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 5     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "        \n",
    "            e_dn = train[d,n] - (item_features[:,d].T).dot(user_features[:,n])\n",
    "            grad_user = e_dn * item_features[:, d] - lambda_user * user_features[:, n]\n",
    "            grad_item =  (e_dn * user_features[:, n] - lambda_item * item_features[:, d])\n",
    "            \n",
    "            item_features[:, d] = item_features[:, d] + gamma * grad_item\n",
    "            user_features[:, n] = user_features[:, n] + gamma * grad_user           \n",
    "                \n",
    "                \n",
    "        regularized_term = lambda_user / 2 * np.linalg.norm(user_features) + lambda_item / 2 * np.linalg.norm(item_features)    \n",
    "        rmse = compute_error(train, user_features, item_features, nz_train) \n",
    "\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "    \n",
    "    \n",
    "    print(\"TEST\")\n",
    "\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))   \n",
    "\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_user_features, predicted_item_features = matrix_factorization_SGD(train, test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \n",
    "    I = np.eye(item_features.shape[0])\n",
    "    item_features_nz = item_features[:, nz_user_itemindices]\n",
    "    train_nz = train[nz_user_itemindices]\n",
    "    \n",
    "    Ai = item_features_nz @ item_features_nz.T + lambda_user * I * nnz_items_per_user\n",
    "    Vi = item_features_nz @ train_nz\n",
    "\n",
    "    updated_user_features = np.linalg.solve(Ai,Vi)\n",
    "        \n",
    "    return updated_user_features.reshape(item_features.shape[0],), Vi\n",
    "    \n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \n",
    "    I = np.eye(user_features.shape[0])\n",
    "    user_features_nz = user_features[:, nz_item_userindices]\n",
    "    train_nz = train[:, nz_item_userindices]\n",
    "    \n",
    "    Ai = user_features_nz @ user_features_nz.T + lambda_item * I * nnz_users_per_item\n",
    "    Vi = user_features_nz @ train_nz.T\n",
    "    \n",
    "    updated_item_features = np.linalg.solve(Ai,Vi)\n",
    "    \n",
    "    return updated_item_features.reshape(user_features.shape[0],), Vi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-3\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    error_list[0] = 1000\n",
    "    \n",
    "    # Calculate arguments for the update of Z and W\n",
    "    nnz_items_per_user = train.getnnz(axis=0)\n",
    "    nnz_users_per_item = train.getnnz(axis=1)\n",
    "    nz_train, nz_row_colindices, nz_col_rowindices = build_index_groups(train)   \n",
    "    \n",
    "    while (abs(error_list[0] - error_list[1]) > stop_criterion):\n",
    "                \n",
    "        # Fix W (item), estimate Z (user)\n",
    "        for i, nz_user_itemindices in nz_col_rowindices:\n",
    "            user_features[:,i], test = update_user_feature(train[:,i], item_features, lambda_user, nnz_items_per_user[i], nz_user_itemindices)\n",
    "\n",
    "        # Fix Z, estimate W\n",
    "        for j, nz_item_userindices in nz_row_colindices:\n",
    "            item_features[:,j], essai = update_item_feature(train[j], user_features, lambda_item, nnz_users_per_item[j], nz_item_userindices)\n",
    "        \n",
    "        nz_row, nz_col = train.nonzero()\n",
    "        nz_train = list(zip(nz_row, nz_col))\n",
    "        error_list[change] = compute_error(train, user_features, item_features, nz_train)\n",
    "    \n",
    "        print(\"RMSE on train data: {}\".format(error_list[change]))\n",
    "    \n",
    "        if(change == 1):\n",
    "            change = 0\n",
    "        else:\n",
    "            change = 1\n",
    "        \n",
    "    print(\"Converged\")\n",
    "    \n",
    "    #print(\"TEST\")\n",
    "    #nz_row_te, nz_col_te = test.nonzero()\n",
    "    #nz_test = list(zip(nz_row_te, nz_col_te))\n",
    "    #rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    #print(\"RMSE on test data: {}.\".format(rmse)) \n",
    "    \n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train data: 1.8913355062031152\n",
      "RMSE on train data: 1.2619562690610293\n",
      "RMSE on train data: 1.139907205950521\n",
      "RMSE on train data: 1.0907730412145573\n",
      "RMSE on train data: 1.066056940884627\n",
      "RMSE on train data: 1.0519818411627135\n",
      "RMSE on train data: 1.0433089121926378\n",
      "RMSE on train data: 1.0376719320328993\n",
      "RMSE on train data: 1.0338686315830397\n",
      "RMSE on train data: 1.0312329346523315\n",
      "RMSE on train data: 1.0293705804503115\n",
      "RMSE on train data: 1.028035825688263\n",
      "RMSE on train data: 1.027069139376757\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "predicted_user_features, predicted_item_features = ALS(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_removed_elements(features, valid_indices, num_elements):\n",
    "    \"\"\"Add removed users or items by replacing it with the mean\"\"\"\n",
    "    \n",
    "    full_features = np.zeros((features.shape[0], num_elements)) + np.mean(features, axis=1).reshape((-1,1))\n",
    "    for i, Vi in enumerate(valid_indices):\n",
    "        full_features[:, Vi] = features[:, i]\n",
    "        \n",
    "    return full_features\n",
    "\n",
    "\n",
    "def unvalid_indexes(total_elements, valid_indices):\n",
    "    \"\"\" Return the corresponding unvalid elements indices. If we remove the elements of \n",
    "                valid_indices in a data set of size total_elements\"\"\"\n",
    "    \n",
    "    return np.delete(range(total_elements),valid_indices)\n",
    "\n",
    "\n",
    "\n",
    "def fill_added_user_features(full_item_features,full_user_features,users_idx_to_calculate,train_full,\n",
    "                             lambda_user, nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix for a specific set of indices\"\"\"\n",
    "    \n",
    "    num_users = train_full.shape[1]\n",
    "    K = full_item_features.shape[0]\n",
    "    \n",
    "    # Calculate usin full_item_features or item_features ?\n",
    "    \n",
    "    for n in users_idx_to_calculate:\n",
    "        nz_item_features_per_user = full_item_features[:, nz_user_itemindices[n]]\n",
    "        A = nz_item_features_per_user @ nz_item_features_per_user.T + nnz_items_per_user[n] * lambda_user*np.eye(K)\n",
    "        ratings_per_user_nz_items=train_full[nz_user_itemindices[n],n] \n",
    "        B = nz_item_features_per_user @ ratings_per_user_nz_items \n",
    "        full_user_features[:, n] = np.linalg.solve(A, B)[:,0] \n",
    "        \n",
    "    return full_user_features\n",
    "\n",
    "\n",
    "def fill_added_item_features(full_item_features,full_user_features,items_idx_to_calculate, train_full, lambda_item,\n",
    "                              nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix for a specific set of indices\"\"\"\n",
    "    num_items = ratings.shape[0]\n",
    "    K = full_user_features.shape[0]\n",
    "    \n",
    "    \n",
    "    # Calculate usin full_user_features or user_features ?\n",
    "    \n",
    "    for d in items_idx_to_calculate:\n",
    "        nz_user_features_per_item = full_user_features[:, nz_item_userindices[d]]\n",
    "        A = nz_user_features_per_item @ nz_user_features_per_item.T + nnz_users_per_item[d]*lambda_item*np.eye(K)\n",
    "        ratings_per_item_nz_users=train_full[d,nz_item_userindices[d]]     \n",
    "        B = nz_user_features_per_item @ ratings_per_item_nz_users.T \n",
    "        full_item_features[:, d] = np.linalg.solve(A, B)[:,0]\n",
    "        \n",
    "    return full_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def constuct_full_features(predicted_user_features, predicted_item_features,\n",
    "                           valid_users_idx, valid_items_idx, \n",
    "                           min_num_ratings, train_full):\n",
    "    \n",
    "    if min_num_ratings == 0:\n",
    "        full_user_features = predicted_user_features\n",
    "        full_item_features = predicted_item_features\n",
    "    \n",
    "    else:\n",
    "        total_num_items,total_num_users = ratings.shape\n",
    "\n",
    "        full_user_features = add_removed_elements(predicted_user_features, valid_users_idx, total_num_users)\n",
    "        full_item_features = add_removed_elements(predicted_item_features, valid_items_idx, total_num_items)\n",
    "        \n",
    "        added_users = unvalid_indexes(total_num_users, valid_users_idx)\n",
    "        added_items = unvalid_indexes(total_num_items, valid_items_idx)\n",
    "        \n",
    "        nnz_items_per_user = train_full.getnnz(axis=0)\n",
    "        nnz_users_per_item = train_full.getnnz(axis=1)\n",
    "        \n",
    "        nz_user_itemindices = []\n",
    "        nz_item_userindices = []\n",
    "        nz_ratings, nz_row_colindices, nz_col_rowindices = build_index_groups(train_full)\n",
    "        \n",
    "        lambda_user = 0.1\n",
    "        lambda_item = 0.7\n",
    "\n",
    "        for row,colindices in nz_row_colindices:\n",
    "            nz_item_userindices.append(colindices)\n",
    "        for col,rowindices in nz_col_rowindices:\n",
    "            nz_user_itemindices.append(rowindices)\n",
    "\n",
    "        full_item_features = fill_added_item_features(full_item_features, full_user_features, added_items, train_full, lambda_item, nnz_users_per_item, nz_item_userindices)  \n",
    "        full_user_features = fill_added_user_features(full_item_features, full_user_features, added_users, train_full, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "\n",
    "    return full_user_features, full_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 9997 9998 9999]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
      " 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972\n",
      " 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990\n",
      " 991 992 993 994 995 996 997 998 999]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 899 is out of bounds for axis 1 with size 899",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-9f6032c6aae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmin_num_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m full_user_features, full_item_features = constuct_full_features(predicted_user_features, predicted_item_features,\n\u001b[1;32m----> 3\u001b[1;33m                                                                 valid_users, valid_items, min_num_ratings, train_full)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-121-0f162e316ba4>\u001b[0m in \u001b[0;36mconstuct_full_features\u001b[1;34m(predicted_user_features, predicted_item_features, valid_users_idx, valid_items_idx, min_num_ratings, train_full)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mfull_user_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_removed_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_user_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_users_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_num_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mfull_item_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_removed_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_item_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_items_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_num_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0madded_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munvalid_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_num_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_users_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-c9551817eefc>\u001b[0m in \u001b[0;36madd_removed_elements\u001b[1;34m(features, valid_indices, num_elements)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfull_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfull_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 899 is out of bounds for axis 1 with size 899"
     ]
    }
   ],
   "source": [
    "min_num_ratings = 10\n",
    "full_user_features, full_item_features = constuct_full_features(predicted_user_features, predicted_item_features,\n",
    "                                                                valid_users, valid_items, min_num_ratings, train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(full_item_features.T @ full_user_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import read_txt, deal_line\n",
    "import csv\n",
    "\n",
    "def create_submission_csv(predictions, sample_submission_filename, submission_filename):\n",
    "    \n",
    "    sample_data = read_txt(sample_submission_filename)[1:]\n",
    "    sample_data = [deal_line(line) for line in sample_data]\n",
    "    \n",
    "    with open(submission_filename, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for user, item,fake_rating in sample_data:\n",
    "            writer.writerow({'Id': \"r{}_c{}\".format(user,item), 'Prediction': predictions[item-1,user-1]})\n",
    "            \n",
    "        #WARNING NEW LINE IN OUPTUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission_csv(full_item_features.T @ full_user_features,\"../Data/sampleSubmission.csv\",\"./submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
